"""=======================
Crispr screen pipeline
=======================

The CRISPR screen pipeline imports reads from crispr screen experiment,
extracts the sgRNA sequences, aligns them to the library, counts the occurences
of each guide in each sample and generates tables to be analysed with R.

Target overview
-----------------

demultiplexing
    fastq.gz files that contain samples from different PCRs are
    demultiplexed according to the stagger sequence in order to create 1 file
    per PCR. This step was needed because 2 of my samples had the same index
    but not the same stagger. I chose to run it only for that sample.

extract_sgRNA
    the different lanes of each sample are merged (Nextseq generate 1 file per
    lane per sample = 4 files per sample) then cutadapt is used to extract the
    sequence corresponding to the sgRNA (removes the sequence upstream then
    cuts 20 nucleotides further independently of the downstream sequence)

MapReads
    uses bowtie or bowtie2 to align the extracted sequence to the library.
    (start by generating the bowtie indexes if doesn't already exist).
    SAMtools are then used to generate a sorted BAM file.

index_bam
    creates bai files associated with output of MapReads

count_sgRNAs
    uses samtools to generate a table containing the number of occurences
    of each sgRNA. The output is TAB-delimited with each line consisting of
    sgRNA ID (gene_sequence), sequence length, # mapped reads and
    # unmapped reads.

count_per_million
    create final table with sgRNA counts and count per million for all samples
    export it as a csv file with 1 row per sgRNA and 5 columns: 
    'gene_sgRNA', 'library', 'sample', 'count', 'cpm'


Usage
------

The working directory need to contains:
    pipeline.ini file
    soft link to script
    soft link to the library file
    a subfolder called 'datafiles' and containing soft links to data (fastq.gz)

The pipeline.ini file contains options for the different commands
    and informations on library name and stagger sequences.
    It can be modified according to specific needs

Read files generated by NextSeq are named:
    LibraryName-Sample_LaneNumber_ReadNumber_001.fastq.gz
    example: V2B-BP-1_S12_L001_R1_001.fastq.gz

Library file need to be a fasta file with:
    >gene_sequence
    sequence

Command line:
    Preview with $ python pipeline_crispr.py show
    Run with $ python pipeline_crispr.py make full

"""
# load modules

import sys
import os
from ruffus import collate, subdivide, transform, regex, suffix, follows, mkdir, merge
import CGATPipelines.Pipeline as P
import pandas as pd
import re

# load options from the config file
PARAMS = P.getParameters(
        ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
         "../pipeline.ini",
         "pipeline.ini"])


@follows(mkdir("wrong_stagger.dir"))
@transform("datafiles/*.fastq.gz",
           regex(r"datafiles/([^-]+)-([^_]+)_(.+).fastq.gz"),
           r"\1-*_\3.fastq.gz")
def demultiplexing(infiles, outfiles):
    '''
    2 of the PCR samples have same index but different staggers.
    We want to separate them according to staggers
    Would probably remove that step from general pipeline
    '''
    mixed_sample = PARAMS['mixedsample']
    staggers = PARAMS['staggers']

    if mixed_sample in infiles:
        output_files = outfiles.replace(r"*", r"{name}")
        untrimmed = P.snip(os.path.basename(infiles), "_R1_001.fastq.gz")

        statement = '''
        cutadapt %(staggers)s
        --no-trim
        %(infiles)s
        -o %(output_files)s
        --untrimmed-o=wrong_stagger.dir/%(untrimmed)s-wrong_stagger.fastq.gz
        >> %(untrimmed)s_demultiplexing.log
        '''
    else:
        statement = '''
        mv %(infiles)s ./
        '''

    P.run()


@follows(demultiplexing,
         mkdir("extracted.dir"),
         mkdir("too_short.dir"),
         mkdir("untrimmed.dir"))
@collate("*.fastq.gz",
         regex(r"(\S*)_L00[1-4]_R1_001.fastq.gz"),
         r"extracted.dir/\1_extracted.fastq.gz")
def sgRNA_extraction(infiles, outfiles):
    '''
    Merge the files corresponding to the 4 lanes for each sample, then extract
    sgRNA sequence from each read with cutadapt.
    The input files are fastq.gz (either unprocessed or demultiplexed).
    The output files are fastq.gz files with sgRNa sequence for each read
    Extracted sequences that are too short and untrimmed reads (adaptor
    sequence not found) are exported in separated folders
    '''
    input_files = ' '.join(infiles)
    track = P.snip(os.path.basename(outfiles), ".fastq.gz")
    adaptor_seq = PARAMS['cutadapt_adaptor_seq']
    options = PARAMS['cutadapt_options']
    statement = '''zcat %(input_files)s |
    cutadapt -g %(adaptor_seq)s
    %(options)s -
    -o %(outfiles)s
    --too-short-o too_short.dir/%(track)s_tooshort.fastq.gz
    --untrimmed-output untrimmed.dir/%(track)s_untrimmed.fastq.gz
    >> %(track)s.log
    '''

    P.run()



###############################################################################
# Read alignment to library (with bowtie or bowtie2)
###############################################################################

mapper = PARAMS['mapper']
library_files = P.asList(PARAMS['libraryfiles'])
library_names = P.asList(PARAMS['librarynames'])
library_dict = dict(zip(library_names, library_files))

if mapper == 'bowtie':

    @follows(mkdir("library.dir"))
    @subdivide(library_files, regex(r"(\S+).fasta"),
               r"library.dir/\1.*.ebwt")
    def BuildBowtieIndex(infiles, outfiles):
        basename = 'library.dir/' + P.snip(os.path.basename(infiles), ".fasta")
        statement = '''
        bowtie-build -f %(infiles)s %(basename)s
        '''

        P.run()


    @follows(BuildBowtieIndex, mkdir("bowtie.dir"))
    @transform(sgRNA_extraction,
               regex(r"extracted.dir/(\S*)_extracted.fastq.gz"),
               r"bowtie.dir/\1_bowtie.bam")
    def MapReads(infiles, outfiles):
        job_threads = PARAMS['bowtie_threads']
        os.environ['BOWTIE_INDEXES'] = './library.dir/'
        input_base = os.path.basename(infiles)
        lib = input_base.split('-')[0]
        sgRNA_library = library_dict[lib]
        basename = P.snip(sgRNA_library, ".fasta")
        options = PARAMS['bowtie_options']
        statement = '''
        bowtie %(options)s
        --threads %(job_threads)s
        %(basename)s
        %(infiles)s
        2> %(outfiles)s.log |
        samtools view -S -u - 2>>%(outfiles)s.log |
        samtools sort -@ %(job_threads)s -T %(input_base)s -o %(outfiles)s 2>>%(outfiles)s.log
	'''

        P.run()



elif mapper == 'bowtie2':

    @follows(mkdir("library.dir"))
    @transform(library_files, regex(r"(\S+).fasta"),
               r"library.dir/1.*.bt2")
    def BuildBowtie2Index(infiles, outfiles):
        basename = 'library.dir/' + P.snip(os.path.basename(infiles), ".fasta")
        statement = '''
        bowtie2-build -f %(infiles)s %(basename)s'''

        P.run()


    @follows(BuildBowtie2Index, mkdir("bowtie2.dir"))
    @transform(sgRNA_extraction,
               regex(r"extracted.dir/(\S+)_extracted.fastq.gz"),
               r"bowtie2.dir/\1_bowtie2.bam")
    def MapReads(infiles, outfiles):
        job_threads = PARAMS['bowtie2_threads']
        os.environ['BOWTIE2_INDEXES'] = './library.dir/'
        input_base = os.path.basename(infiles)
        lib = input_base.split('-')[0]
        sgRNA_library = library_dict[lib]
        basename = P.snip(sgRNA_library, ".fasta")
        options = PARAMS['bowtie2_options']
        statement = '''
        bowtie2 %(options)s
        --threads %(job_threads)s
        -x %(basename)s
        -U %(infiles)s
        2> %(outfiles)s.log |
        samtools view -u 2>>%(outfiles)s.log |
        samtools sort -@ %(job_threads)s -T %(input_base)s -o %(outfiles)s 2>>%(outfiles)s.log
        '''

        P.run()

else:
    raise ValueError("Unknown mapper: %s" % mapper)



# Index the sorted BAM file and create index file (.bam.bai)
@transform(MapReads,
           suffix(".bam"),
           ".bam.bai")
def index_bam(infile, outfile):

    statement = '''samtools index %(infile)s > %(outfile)s 2>%(outfile)s.log '''

    P.run()


###############################################################################
# Generate read counts and final table with CPMs
###############################################################################

experiment = PARAMS['experiment']

# follows: wait for the index file to be created before to run next command
# then compute statistics about the bam file and export them to tsv file
@follows(index_bam, mkdir('sgRNA_counts.dir'))
@transform(MapReads,
           regex(r"bowtie2?.dir/(\S+).bam"),
           r"sgRNA_counts.dir/\1.tsv")
def count_sgRNAs(infile, outfile):

    statement = '''samtools idxstats %(infile)s > %(outfile)s '''

    P.run()


# open all count tables one by one, calculate cpm, keep only information needed
# export 1 table per sample with read count and cpm 
# also create a final table with cpms for all samples
@merge(count_sgRNAs, 
       "sgRNA_counts.dir/%s_%s_final_table.csv" % (experiment, mapper))
def count_per_million(infiles, outfile):
    final_cpm_table = pd.DataFrame(columns=
                               ['gene_sgRNA', 'library', 'sample', 'count', 'cpm'])
    for infile in infiles:
        m = re.match(r'sgRNA_counts.dir/(\S+?)-(\S+?)_.*(bowtie2?).tsv', infile)
        lib = m.group(1)
        sample = m.group(2)
        df = pd.read_table(infile, header = None,
                       names = ['gene_sgRNA', 'length', 'count', 'missing'],
                       usecols = ['gene_sgRNA', 'count'])
        count_sum = df['count'].sum()
        df['cpm'] = 1000000*df['count']/count_sum
        df['library'] = lib
        df['sample'] = sample
        df = df[['gene_sgRNA', 'library', 'sample', 'count', 'cpm']]
        individual_output = P.snip(infile, '.tsv')+'_cpm.csv'
        df.to_csv(individual_output, header=True, index=False)
        final_cpm_table = final_cpm_table.append(df)
    
    final_cpm_table.to_csv(outfile, index=False)

   # P.run()



@follows(count_per_million)
def full():
        pass


def main(argv=None):
        if argv is None:
                argv = sys.argv
        P.main(argv)


if __name__ == "__main__":
        sys.exit(P.main(sys.argv))
